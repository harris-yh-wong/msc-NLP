{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Harris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Harris\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove\n",
    "from zeugma.embeddings import EmbeddingTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "# Classifiers\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# ## and for evaluation\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn import metrics\n",
    "# from sklearn.model_selection import cross_validate\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import clone\n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = Path('.')/'..'/'..'\n",
    "source_data_dir = proj_dir/'data'/'source'\n",
    "clean_data_dir  = proj_dir/'data'/'clean'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Process source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 30135 lines from ..\\..\\data\\source\\pubmed\\test.txt\n",
      "Wrote 30135 lines to ..\\..\\data\\clean\\pubmed\\test_processed.txt\n",
      "Read 180040 lines from ..\\..\\data\\source\\pubmed\\train.txt\n",
      "Wrote 180040 lines to ..\\..\\data\\clean\\pubmed\\train_processed.txt\n",
      "Read 30212 lines from ..\\..\\data\\source\\pubmed\\dev.txt\n",
      "Wrote 30212 lines to ..\\..\\data\\clean\\pubmed\\dev_processed.txt\n"
     ]
    }
   ],
   "source": [
    "preprocessing.process_source_files(input_dir = source_data_dir/'pubmed', output_dir = clean_data_dir/'pubmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>label</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>24496960</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>The efficacy of this dosing algorithm was eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>25728891</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>Several studies suggest that surgical manipula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>25070400</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>At both follow-ups an uncorrected distance and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>25262788</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Patients were followed up at 1 , 3 and 6 month...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>25464438</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>To assess whether AHA are directly pathogenic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>24953916</td>\n",
       "      <td>METHODS</td>\n",
       "      <td>Department of Plastic Surgery and Burns Unit ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>25224756</td>\n",
       "      <td>BACKGROUND</td>\n",
       "      <td>Community health workers ( CHWs ) have been ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>24477028</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>While this study was too underpowered to deter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>25351765</td>\n",
       "      <td>CONCLUSIONS</td>\n",
       "      <td>This study will supply significant evidence fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>25424601</td>\n",
       "      <td>RESULTS</td>\n",
       "      <td>Although there was no significant association ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pmid        label                                                txt\n",
       "NaN  24496960      METHODS  The efficacy of this dosing algorithm was eval...\n",
       "NaN  25728891   BACKGROUND  Several studies suggest that surgical manipula...\n",
       "NaN  25070400      RESULTS  At both follow-ups an uncorrected distance and...\n",
       "NaN  25262788      METHODS  Patients were followed up at 1 , 3 and 6 month...\n",
       "NaN  25464438   BACKGROUND  To assess whether AHA are directly pathogenic ...\n",
       "NaN  24953916      METHODS  Department of Plastic Surgery and Burns Unit ,...\n",
       "NaN  25224756   BACKGROUND  Community health workers ( CHWs ) have been ef...\n",
       "NaN  24477028  CONCLUSIONS  While this study was too underpowered to deter...\n",
       "NaN  25351765  CONCLUSIONS  This study will supply significant evidence fo...\n",
       "NaN  25424601      RESULTS  Although there was no significant association ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Import data\n",
    "train, dev, test = preprocessing.import_processed_files(dir=clean_data_dir/'pubmed')\n",
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"regexes.json\") as fp:\n",
    "    regexes = json.load(fp)\n",
    "\n",
    "pprint(regexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = {}\n",
    "\n",
    "# BoW\n",
    "vectorizer = CountVectorizer(\n",
    "    ngram_range=(1,1), \n",
    "    stop_words=None,\n",
    "    tokenizer=word_tokenize, \n",
    "    max_features=500\n",
    ")\n",
    "xtrain_countvect = vectorizer.fit_transform(trainingdata['txt'])\n",
    "representations['CountVectorizer'] = xtrain_countvect\n",
    "\n",
    "# tfidf\n",
    "tfidf_vect = TfidfVectorizer(\n",
    "    tokenizer=word_tokenize, \n",
    "    stop_words=stopWords\n",
    ")\n",
    "tfidf_vect.fit(trainingdata['txt'])\n",
    "xtrain_tfidf = tfidf_vect.transform(trainingdata['txt'])\n",
    "representations['TfidfVectorizer'] = xtrain_tfidf\n",
    "\n",
    "# glove\n",
    "x_train_glove = glove.transform(trainingdata['txt'])\n",
    "representations['pretrained_glove'] = x_train_glove\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation\n",
    "\n",
    "punctuations = string.punctuation \n",
    "punctuations = [char for char in punctuations if char != '.' and char != ',' and char != '-']\n",
    "punctuations = ''.join(punctuations)\n",
    "punctuations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('msc-NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6ca4a5427f6f904b0fb59ebe4723ed6fa2277abd3f62b239565a58ff4c14b3b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
